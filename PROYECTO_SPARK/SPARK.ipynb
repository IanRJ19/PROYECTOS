{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CSV-TRABAJAR CON SPARK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#COnfiguración esencial\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SESION')\\\n",
    "    .config('spark.master', 'local[6]')\\\n",
    "    .config('spark.executor.memory', '6g')\\\n",
    "    .config(\"spark.sql.shuffle.partitions\", 1)\\\n",
    "    .config('spark.driver.memory','6g')\\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", True)\\\n",
    "    .getOrCreate()\n",
    "\n",
    "path = \"C:/Users/Rayzek/Desktop/Nueva carpeta/ReporteTerminales 2022.11.21.csv\"\n",
    "df = spark.read.option(\"delimiter\", \";\").csv(path)\n",
    "df.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CSV-TRABAJAR CON SPARK Y LUEGO PASAR A PANDAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COnfiguración esencial\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SESION')\\\n",
    "    .config('spark.master', 'local[6]')\\\n",
    "    .config('spark.executor.memory', '6g')\\\n",
    "    .config(\"spark.sql.shuffle.partitions\", 1)\\\n",
    "    .config('spark.driver.memory','6g')\\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", True)\\\n",
    "    .getOrCreate()\n",
    "\n",
    "path = \"C:/Users/Rayzek/Desktop/Nueva carpeta/ReporteTerminales 2022.11.21.csv\"\n",
    "df = spark.read.option(\"delimiter\", \";\").csv(path)\n",
    "\n",
    "import pyspark.pandas as ps\n",
    "ds=df.toPandas()\n",
    "cabeza=ds.iloc[2]\n",
    "ds=ds[3:]\n",
    "ds.columns=cabeza\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CSV-TRABAJAR CON MÉTODO TRADICIONAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"C:/Users/Rayzek/Desktop/Nueva carpeta/ReporteTerminales 2022.11.21.csv\"\n",
    "da=pd.read_csv(path,sep=';', encoding='latin-1')\n",
    "cabeza=da.iloc[1]\n",
    "da=da[2:]\n",
    "da.columns=cabeza\n",
    "da.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EXCEL-TRABAJAR CON SPARK-PANDAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.pandas as ps\n",
    "# Enable Arrow-based columnar data transfers\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "\n",
    "path = \"C:/Users/Rayzek/Desktop/Nueva carpeta/ReporteTerminales 2022.11.21.xlsx\"\n",
    "da=ps.read_excel(\"C:/Users/Rayzek/Desktop/Nueva carpeta/ReporteTerminales 2022.11.21.xlsx\")\n",
    "cabeza=da.iloc[1]\n",
    "da=da[2:]\n",
    "da.columns=cabeza\n",
    "da.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EXCEL-TRABAJAR CON SPARK-PANDAS + PYARROW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Enable Arrow-based columnar data transfers\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "\n",
    "# Convert the Spark DataFrame back to a Pandas DataFrame using Arrow\n",
    "PANDITA = df.select(\"*\").toPandas()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EXCEL-TRABAJAR CON MÉTODO TRADICIONAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"C:/Users/Rayzek/Desktop/Nueva carpeta/ReporteTerminales 2022.11.21.xlsx\"\n",
    "da=pd.read_excel(\"C:/Users/Rayzek/Desktop/Nueva carpeta/ReporteTerminales 2022.11.21.xlsx\")\n",
    "cabeza=da.iloc[1]\n",
    "da=da[2:]\n",
    "da.columns=cabeza\n",
    "da.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xlsx2csv import Xlsx2csv\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "\n",
    "path=\"C:/Users/Rayzek/Desktop/Nueva carpeta/ReporteArticulos 2022.12.13.xlsx\"\n",
    "\n",
    "def read_excel(path: str, sheet_name: str) -> pd.DataFrame:\n",
    "    buffer = StringIO()\n",
    "    Xlsx2csv(path, outputencoding=\"utf-8\", sheet_name=sheet_name).convert(buffer)\n",
    "    buffer.seek(0)\n",
    "    agentes = pd.read_csv(buffer)\n",
    "    return agentes\n",
    "\n",
    "a=read_excel(path,\"Hoja1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COnfiguración esencial\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SESION')\\\n",
    "    .config('spark.master', 'local[6]')\\\n",
    "    .config('spark.executor.memory', '6g')\\\n",
    "    .config(\"spark.sql.shuffle.partitions\", 1)\\\n",
    "    .config('spark.driver.memory','6g')\\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", True)\\\n",
    "    .getOrCreate()\n",
    "\n",
    "path = \"C:/Users/Rayzek/Desktop/Nueva carpeta/ReporteTerminales 2022.11.21.csv\"\n",
    "df = spark.read.option(\"delimiter\", \";\").csv(path)\n",
    "df.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f501586d3d6585364b3c782eb6f8798ead6c56dd0ce00d45a4fd8b1c0d4f0e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
